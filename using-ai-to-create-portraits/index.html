<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1"><meta name="robots" content="noodp"/><title>GANArt: Using AI to create Portraits | </title><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/sample.gif"/>
<meta name="twitter:title" content="GANArt: Using AI to create Portraits"/>
<meta name="twitter:description" content="Hugo provides "/><meta name="Description" content="Hugo provides "><meta property="og:title" content="GANArt: Using AI to create Portraits" />
<meta property="og:description" content="Hugo provides " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/" /><meta property="og:image" content="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/feature-image.jpg"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-06-25T16:29:41&#43;08:00" />
<meta property="article:modified_time" content="2021-06-25T16:29:41&#43;08:00" />

<meta name="application-name" content="DC">
<meta name="apple-mobile-web-app-title" content="DC"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
        <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
        <link rel="icon" type="image/png" sizes="512x512" href="/android-chrome-512x512.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/lib/prismjs/prism.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "GANArt: Using AI to create Portraits",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/DeewakarChakraborty.github.io\/using-ai-to-create-portraits\/"
        },"image": [{
                            "@type": "ImageObject",
                            "url": "https:\/\/DeewakarChakraborty.github.io\/using-ai-to-create-portraits\/sample.gif",
                            "width":  1000 ,
                            "height":  533 
                        }],"genre": "posts","wordCount":  1259 ,
        "url": "https:\/\/DeewakarChakraborty.github.io\/using-ai-to-create-portraits\/","datePublished": "2021-06-25T16:29:41+08:00","dateModified": "2021-06-25T16:29:41+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.",
        "publisher": {
            "@type": "Person",
            "name": "", "image": [
            {
            "@type": "ImageObject",
            "url": "https:\/\/upagge.ru\/img\/ava.jpg"
            }
            ]},"author": {
                "@type": "Person",
                "name": ""
            },"description": "Hugo provides "
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script>(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header>
    <div class="desktop header" id="header-desktop">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Deewakar&#39;s Blog" class="header-logo logo-svg"><span class="header-title-pre"><i class='fas fa-pencil-alt fa-fw'></i></span>HOME</a>
            </div>
            <div class="menu">
                <nav>
                    <h2 class="display-hidden">Основная навигация</h2>
                    <ul class="menu-inner"><li>
                            <a class="menu-item" href="/posts/"> Blog </a>
                        </li><li>
                            <a class="menu-item" href="/projects/"> Projects </a>
                        </li><li>
                            <a class="menu-item" href="/about/"> About Me </a>
                        </li></ul>
                </nav><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <span class="svg-icon icon-search"></span>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <span class="svg-icon icon-cancel"></span>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <span class="svg-icon icon-loading"></span>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <span class="svg-icon icon-moon"></span>
                </a>
            </div>
        </div>
    </div><div class="mobile header" id="header-mobile">
        <div class="header-container">
            <div class="header-wrapper">
                <div class="header-title">
                    <a href="/" title="Deewakar&#39;s Blog" class="header-logo"><span class="header-title-pre"><i class='fas fa-pencil-alt fa-fw'></i></span>HOME</a>
                </div>
                <div class="menu-toggle" id="menu-toggle-mobile">
                    <span></span><span></span><span></span>
                </div>
            </div>
            <div class="menu" id="menu-mobile"><div class="search-wrapper">
                        <div class="search mobile" id="search-mobile">
                            <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                                <span class="svg-icon icon-search"></span>
                            </a>
                            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                                <span class="svg-icon icon-cancel"></span>
                            </a>
                            <span class="search-button search-loading" id="search-loading-mobile">
                                <span class="svg-icon icon-loading"></span>
                            </span>
                        </div>
                        <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                            Cancel
                        </a>
                    </div><nav>
                    <h2 class="display-hidden">Основная навигация</h2>
                    <ul><li>
                            <a class="menu-item" href="/posts/" title="">Blog</a>
                        </li><li>
                            <a class="menu-item" href="/projects/" title="">Projects</a>
                        </li><li>
                            <a class="menu-item" href="/about/" title="">About Me</a>
                        </li></ul>
                </nav>
                <a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <span class="svg-icon icon-moon"></span>
                </a></div>
        </div>
    </div><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div></header><main class="main">
<div class="container content-article page-toc theme-classic"><div class="toc" id="toc-auto">
            <div class="toc-title">Contents</div>
            <div class="toc-content" id="toc-content-auto"></div>
        </div>
    

    
    
    <article>
    

        <header class="header-post">

            

            
            <div class="post-title">

                    <div class="post-all-meta">
                        <nav class="breadcrumbs">
    <ol>
        <li><a href="/">Home </a></li><li>GANArt: Using AI to create Portraits</li>
    </ol>
</nav>
                        <h1 class="single-title flipInX">GANArt: Using AI to create Portraits</h1><div class="post-meta summary-post-meta"><span class="post-meta-date meta-item">
                                <span class="svg-icon icon-clock"></span><time class="timeago" datetime="2021-06-25">2021-06-25</time>
                            </span><span class="post-meta-words meta-item">
                                <span class="svg-icon icon-pencil"></span>1259 words
                            </span>
                            <span class="post-meta-reading meta-item">
                                <span class="svg-icon icon-stopwatch"></span>6 minutes
                            </span>
                        </div>

                    </div>

                </div>

                </header>

        <div class="article-post toc-start">

            <div class="content-block content-block-first content-block-position">

                <div class="post single"><div class="image-theme-classic">
                        <img src="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/sample.gif" style="width: 100%">
                    </div><div class="details toc" id="toc-static"  data-kept="">
                        <div class="details-summary toc-title">
                            <span>Contents</span>
                        </div>
                        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#data-collection">Data Collection</a></li>
    <li><a href="#data-preprocessing">Data Preprocessing</a>
      <ul>
        <li><a href="#preprocessing--the--paintings">Preprocessing  the  paintings</a></li>
        <li><a href="#performing-data-augmentation">Performing Data Augmentation</a></li>
        <li><a href="#transforming-images-into-tfrecords">Transforming images into TF.Records</a></li>
      </ul>
    </li>
    <li><a href="#training-the-model">Training the model</a></li>
    <li><a href="#generating-portraits">Generating Portraits</a></li>
    <li><a href="#use-of--transfer-learning">Use of  Transfer Learning</a></li>
    <li><a href="#some-interesting-incidents">Some Interesting Incidents</a></li>
    <li><a href="#acknowledgement">Acknowledgement</a></li>
  </ul>
</nav></div>
                    </div><blockquote>
<p>This blog is about my project <strong>‘GANArt: Using AI to create Portraits,’</strong> for which I have used various public domain portraits between 1750 to 1950 to train the AI model. The model then adapts the art style and then generates new unique portraits on its own.</p>
</blockquote>
<p>GAN(Generative Adversarial Network) is no wonder an amazing discovery in the field of Deep Learning. From generating fake human faces to an entirely new virtual world, if there is room for creativity, one can indeed implement GAN. This fascination of mine towards Generative Modelling, and in particular GAN, led me towards this creative project.</p>
<p>There are many works already where people have applied GAN in the field of Arts, from abstract arts to genre-specific paintings(using <i>Conditional GANs</i>), and some of these works inspired me to dig deeper into the field of GAN.</p>
<p>For this project, I have used Nvidia&rsquo;s <a href="https://arxiv.org/pdf/2006.06676.pdf" target="_blank" rel="noopener noreffer">StyleGAN2 ADA model</a>, StyleGAN2 is an upgraded version of its earlier model <a href="https://arxiv.org/pdf/1812.04948.pdf" target="_blank" rel="noopener noreffer">StyleGAN</a>, as we know training a GAN using too little data typically leads to discriminator overfitting, causing training to diverge, and therefore, Nvidia came up with the idea of adaptive discriminator augmentation (ADA) and solved the issue of discriminator overfitting.</p>
<p>You can find the Github repository for this project <a href="https://github.com/DeewakarChakraborty/GANArt-Using-AI-to-create-Portraits" target="_blank" rel="noopener noreffer">here</a>.</p>
<h2 id="data-collection" class="headerLink"><a href="#data-collection" class="header-mark"></a>Data Collection</h2><p>The first and foremost challenge for such a project is to collect the training data. For this, I have scrapped data from <a href="https://www.wikiart.org/" target="_blank" rel="noopener noreffer">Wikiart</a>. It is an online, user-editable visual art encyclopedia. I have scrapped only those paintings which are available in the public domain to avoid copyright infringement. For data scrapping, I have used the <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noopener noreffer">Beautiful Soup</a> library. I have picked almost all the paintings between 1850 to 1950 under the category of <em>Portraits</em> and <em>Self-Portraits</em>.</p>
<p>I have uploaded the scrapped data on kaggle. Here is the <a href="https://www.kaggle.com/deewakarchakraborty/portrait-paintings" target="_blank" rel="noopener noreffer">link</a> for the dataset.</p>
<p>Few sample paintings from the dataset.</p>
<center>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="data1.jpg"
         alt="1"
         title="data1.jpg"
    /></p>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="data3.jpg"
         alt="1"
         title="data3.jpg"
    /></p>
</center>
<h2 id="data-preprocessing" class="headerLink"><a href="#data-preprocessing" class="header-mark"></a>Data Preprocessing</h2><p>Once data has been scrapped, all we need to do is to preprocess it. All the images that have been scrapped will have different aspect ratios and resolutions, which we have to make uniform before feeding it to the model. Also, most of the paintings have frames at their borders which we need to remove.</p>
<h3 id="preprocessing--the--paintings" class="headerLink"><a href="#preprocessing--the--paintings" class="header-mark"></a>Preprocessing  the  paintings</h3><p>So for this project, I have decided the resolution of generated portrait to be 512 X 512, but all the scrapped paintings will have different resolutions. Thus, we need to ensure that all the input paintings are to the model of uniform resolution 512 X 512. Following is the code snippet for preparing images:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Importing necessary libraries</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">from_path</span> <span class="o">=</span> <span class="s1">&#39;art/cropped/&#39;</span> <span class="c1">#directory of scrapped paintings </span>
<span class="n">to_path</span> <span class="o">=</span> <span class="s1">&#39;art/resized/&#39;</span>   <span class="c1">#directory of resized paintings</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1">#Required resolution</span>

<span class="n">path</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">from_path</span><span class="p">))</span>
<span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">files</span><span class="p">):</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s2">&#34;/&#34;</span> <span class="o">+</span> <span class="nb">file</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&#34;RGB&#34;</span><span class="p">:</span>
    <span class="n">image_resized</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">),</span> <span class="n">resample</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">)</span>
    <span class="n">image_resized</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">to_path</span> <span class="o">+</span> <span class="s2">&#34;/&#34;</span> <span class="o">+</span> <span class="nb">file</span><span class="p">)</span> <span class="c1">#Saving the resized images </span>
</code></pre></td></tr></table>
</div>
</div><center>
<p>






<img loading="lazy" decoding="async"
         class="render-image"
         src="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/reals_hub3fcedef429d4429c9c6f96ba73592e6_4870292_1600x0_resize_q100_box.jpg"
         alt="image5"
         title="reals.jpg"
    /></p>
<p><i> (After resizing the images, all images are of  </i>512 X 512 <i>resolution.) </i></p>
</center>
<h3 id="performing-data-augmentation" class="headerLink"><a href="#performing-data-augmentation" class="header-mark"></a>Performing Data Augmentation</h3><p>After performing initial scrapping, I have fetched around 1100 paintings. Therefore, to increase the volume of training data, I have performed some data augmentation on scrapped paintings. For data augmentation, I have used the <a href="https://imgaug.readthedocs.io/en/latest/" target="_blank" rel="noopener noreffer">imgaug</a> library. Following is the code snippet for data augmentation:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">imgaug</span> <span class="kn">import</span> <span class="n">augmenters</span> <span class="k">as</span> <span class="n">iaa</span>

<span class="n">num_augmentations</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1">#Number of augmentations that I want</span>

<span class="c1">#Image Augmenter</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">iaa</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">iaa</span><span class="o">.</span><span class="n">Fliplr</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">iaa</span><span class="o">.</span><span class="n">PerspectiveTransform</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;replicate&#39;</span><span class="p">),</span>
    <span class="n">iaa</span><span class="o">.</span><span class="n">AddToHueAndSaturation</span><span class="p">((</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></td></tr></table>
</div>
</div><p>The reason behind using the number of augmentations as 2 is just heuristics. I have used the StyleGAN2 ADA model, this model has adaptive discriminator augmentation that will take care of further necessary augmentation.</p>
<h3 id="transforming-images-into-tfrecords" class="headerLink"><a href="#transforming-images-into-tfrecords" class="header-mark"></a>Transforming images into TF.Records</h3><p>One another step in pre-processing is to transform the images into TF.records(creating the dataset). Again, Nvidia’s StyleGAN2 has an inbuilt option to create the dataset. First and foremost, we have to make sure we are using the TensorFlow 1.x version because Nvidia continued using this version of the TensorFlow.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="o">%</span><span class="n">tensorflow_version</span> <span class="mf">1.</span><span class="n">x</span>
</code></pre></td></tr></table>
</div>
</div><p>Following is the code snippet for creating the dataset:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#First of all we have to clone Nvidia&#39;s StyleGAN2 repo</span>
<span class="o">%</span><span class="n">cd</span> <span class="s2">&#34;/content/drive/My Drive/Project&#34;</span> <span class="c1">#directory of my project</span>
<span class="err">!</span><span class="n">mkdir</span> <span class="n">colab</span><span class="o">-</span><span class="n">sg2</span><span class="o">-</span><span class="n">ada</span>
<span class="o">%</span><span class="n">cd</span> <span class="n">colab</span><span class="o">-</span><span class="n">sg2</span><span class="o">-</span><span class="n">ada</span>
<span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">dvschultz</span><span class="o">/</span><span class="n">stylegan2</span><span class="o">-</span><span class="n">ada</span>

<span class="c1">#command for creating dataset</span>
<span class="err">!</span><span class="n">python</span> <span class="n">dataset_tool</span><span class="o">.</span><span class="n">py</span> <span class="n">create_from_images</span> <span class="s2">&#34;/content/drive/My Drive/Project/Images&#34;</span> <span class="s1">&#39;/content/drive/My Drive/Project/Dataset&#39;</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="training-the-model" class="headerLink"><a href="#training-the-model" class="header-mark"></a>Training the model</h2><p>Once we have the dataset, the next task is to train the model using the dataset. I have used Nvidia’s <a href="https://arxiv.org/pdf/2006.06676.pdf" target="_blank" rel="noopener noreffer">StyleGAN2 ADA</a> model. StyleGAN is one of the most popular generative models by NVIDIA. Multiple versions of StlyeGAN have been released, and I have used the latest version, StyleGAN2-ADA. Training StyleGAN is computationally expensive; therefore, I have used Google colab pro to train the model. It took roughly two days to train the model. To train this model, make sure you are inside the directory of the cloned repository.</p>
<p>Now, for training, we have to set specific hyperparameters.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#how often should the model generate samples and a .pkl file</span>
<span class="n">snapshot_count</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1">#should the images be mirrored left to right?</span>
<span class="n">mirrored</span> <span class="o">=</span> <span class="bp">True</span>
<span class="c1">#should the images be mirrored top to bottom?</span>
<span class="n">mirroredY</span> <span class="o">=</span> <span class="bp">False</span>
<span class="c1">#metrics? </span>
<span class="n">metric_list</span> <span class="o">=</span> <span class="bp">None</span>
<span class="c1">#augments</span>
<span class="n">augs</span> <span class="o">=</span> <span class="s2">&#34;bg&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>Note that if your GPU is not that powerful, keep snapshot_count as minimum as possible(for, e.g., 5) and keep the metric_list as none. Now once you have set the hyperparameters, you can start the training process.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">outdir</span><span class="o">=</span><span class="s1">&#39;/content/drive/MyDrive/Kaggle/Portrait/Results&#39;</span> <span class="o">--</span><span class="n">snap</span><span class="o">=</span><span class="n">snapshot_count</span>  <span class="o">--</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;/content/drive/MyDrive/Kaggle/Portrait/Dataset_TF&#39;</span> <span class="o">--</span><span class="n">augpipe</span><span class="o">=</span><span class="n">augs</span> <span class="o">--</span><span class="n">mirror</span><span class="o">=</span><span class="n">mirrored</span>  <span class="o">--</span><span class="n">mirrory</span><span class="o">=</span><span class="n">mirroredY</span> <span class="o">--</span><span class="n">metrics</span><span class="o">=</span><span class="n">metric_list</span> 
</code></pre></td></tr></table>
</div>
</div><p>Now, once training has started, a new folder will be created inside the folder Results(in my case), and after every ten ticks, a .pkl will be saved there to represent the trained model.</p>
<p><b>When to stop training?</b></p>
<p>There is no specific metric to judge the training when it comes to Generative Modelling. What I did, was to check after every few hours the status of the snapshot. the training process yields the output of the model along with saving its .pkl file. I kept checking the output, and when it finally started to resemble the portraits after a day or two, I stopped the training process as training further was not improving the output anymore.</p>
<h2 id="generating-portraits" class="headerLink"><a href="#generating-portraits" class="header-mark"></a>Generating Portraits</h2><p>Now once you have trained the model, it is ready to generate portraits on its own. All you have to do is provide the random seed values to the generator. The generator will then produce portraits based on the given seed values.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">python</span> <span class="n">generate</span><span class="o">.</span><span class="n">py</span> <span class="n">generate</span><span class="o">-</span><span class="n">images</span> <span class="o">--</span><span class="n">network</span><span class="o">=</span><span class="s1">&#39;/content/drive/MyDrive/Kaggle/Portrait/Results/final_model.pkl&#39;</span> <span class="o">--</span><span class="n">seeds</span><span class="o">=</span><span class="mi">6600</span><span class="o">-</span><span class="mi">6625</span> <span class="o">--</span><span class="n">outdir</span><span class="o">=</span><span class="s1">&#39;/content/drive/MyDrive/Kaggle/Portrait/Output&#39;</span>
</code></pre></td></tr></table>
</div>
</div><p>In this case, I have provided seed values from 6600-6625. This will generate 25 portraits.</p>
<p>Some of the generated portraits.</p>
<center>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="seed6603.png"
         alt="image1"
         title="seed6603.png"
    /></p>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="seed6617.png"
         alt="image2"
         title="seed6617.png"
    /></p>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="seed6622.png"
         alt="image2"
         title="seed6622.png"
    /></p>
</center>
<h2 id="use-of--transfer-learning" class="headerLink"><a href="#use-of--transfer-learning" class="header-mark"></a>Use of  Transfer Learning</h2><p>Once I finished training the model, I also tried the approach of Transfer Learning. Firstly I collected some random human faces that don&rsquo;t exist. Once the dataset was ready, I used the trained model as a starting point and fine-tuned the model. Following are some sample portraits generated by the transfer learning model.</p>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="seed6611.png"
         alt="image4"
         title="seed6611.png"
    /></p>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="seed6619.png"
         alt="image5"
         title="seed6619.png"
    /></p>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="seed6604.png"
         alt="image4"
         title="seed6604.png"
    /></p>
<h2 id="some-interesting-incidents" class="headerLink"><a href="#some-interesting-incidents" class="header-mark"></a>Some Interesting Incidents</h2><p>So somewhere in between the training process, I found out a bizarre incident. Even though there were no paintings related to Jesus Christ in the dataset, it turns out in between the training process; there was a generated portrait resembling Jesus during the training process. GAN&rsquo;s can be very interesting, but at the same time, they can produce unexplainable outcomes.</p>
<center>
<p>




<img loading="lazy" decoding="async"
         class="render-image"
         src="sc.JPG"
         alt="image7"
         title="sc.jpg"
    /></p>
</center>
<h2 id="acknowledgement" class="headerLink"><a href="#acknowledgement" class="header-mark"></a>Acknowledgement</h2><ul>
<li>‘GANs in Action’ by Jakub Langr and Vladimir Bok.</li>
<li>MachineRay: Using AI to create Abstract art by <a href="https://github.com/robgon-art" target="_blank" rel="noopener noreffer">Robert A. Gonsalves</a></li>
</ul>
</div><footer>
                        <div class="post">


<div class="post-share"><div class="share-link">
        <a class="share-icon share-twitter" href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/" data-title="GANArt: Using AI to create Portraits"><span class="svg-social-icon icon-twitter"></span></a>
    </div><div class="share-link">
        <a class="share-icon share-whatsapp" href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://DeewakarChakraborty.github.io/using-ai-to-create-portraits/" data-title="GANArt: Using AI to create Portraits" data-web><span class="svg-social-icon icon-whatsapp"></span></a>
    </div></div>

</div>
                </footer></div>
        <div id="toc-final"></div>
        </div>

    
    </article>
    <section class="page single comments content-block-position">
        <h1 class="display-hidden">Комментарии</h1><div id="comments"><div id="remark42" class="comment" style="padding-top: 1.5rem"></div>
            <script>
                var themeRemark = document.body.getAttribute('theme')
                var remark_config = {
                    host: 'https:\/\/comments.upagge.ru',
                    site_id: 'documentation',
                    components: ['embed'],
                    theme: themeRemark,
                    locale: 'en',
                    show_email_subscription: null ,
                    page_title: 'GANArt: Using AI to create Portraits',
                };

                (function(c) {
                    for(var i = 0; i < c.length; i++){
                        var d = document, s = d.createElement('script');
                        s.src = remark_config.host + '/web/' +c[i] +'.js';
                        s.defer = true;
                        (d.head || d.body).appendChild(s);
                    }
                })(remark_config.components || ['embed']);
            </script></div></section></div>

</main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Deewakar Chakraborty|Pune,IN</div>
        </div>
    </footer></div>

        <aside id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="svg-icon icon-arrow-up"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="svg-icon icon-comments-fixed"></i>
            </a>
        </aside><script src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script src="/lib/prismjs/prism.js"></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.en","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"algolia"}};</script><script src="/js/theme.min.js"></script></body>
</html>
