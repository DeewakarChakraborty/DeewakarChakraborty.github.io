[{"categories":null,"content":"Hugo provides ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":" This blog is about my project ‘GANArt: Using AI to create Portraits,’ for which I have used various public domain portraits between 1750 to 1950 to train the AI model. The model then adapts the art style and then generates new unique portraits on its own. GAN(Generative Adversarial Network) is no wonder an amazing discovery in the field of Deep Learning. From generating fake human faces to an entirely new virtual world, if there is room for creativity, one can indeed implement GAN. This fascination of mine towards Generative Modelling, and in particular GAN, led me towards this creative project. There are many works already where people have applied GAN in the field of Arts, from abstract arts to genre-specific paintings(using Conditional GANs), and some of these works inspired me to dig deeper into the field of GAN. For this project, I have used Nvidia’s StyleGAN2 ADA model, StyleGAN2 is an upgraded version of its earlier model StyleGAN, as we know training a GAN using too little data typically leads to discriminator overfitting, causing training to diverge, and therefore, Nvidia came up with the idea of adaptive discriminator augmentation (ADA) and solved the issue of discriminator overfitting. You can find the Github repository for this project here. ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:0:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Data CollectionThe first and foremost challenge for such a project is to collect the training data. For this, I have scrapped data from Wikiart. It is an online, user-editable visual art encyclopedia. I have scrapped only those paintings which are available in the public domain to avoid copyright infringement. For data scrapping, I have used the Beautiful Soup library. I have picked almost all the paintings between 1850 to 1950 under the category of Portraits and Self-Portraits. I have uploaded the scrapped data on kaggle. Here is the link for the dataset. Few sample paintings from the dataset. \r\r\r\r","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:1:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Data PreprocessingOnce data has been scrapped, all we need to do is to preprocess it. All the images that have been scrapped will have different aspect ratios and resolutions, which we have to make uniform before feeding it to the model. Also, most of the paintings have frames at their borders which we need to remove. ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:2:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Preprocessing the paintingsSo for this project, I have decided the resolution of generated portrait to be 512 X 512, but all the scrapped paintings will have different resolutions. Thus, we need to ensure that all the input paintings are to the model of uniform resolution 512 X 512. Following is the code snippet for preparing images: # Importing necessary libraries import os from PIL import Image import numpy as np from_path = 'art/cropped/' #directory of scrapped paintings to_path = 'art/resized/' #directory of resized paintings size = 512 #Required resolution path, dirs, files = next(os.walk(from_path)) for file in sorted(files): image = Image.open(path + \"/\" + file) if image.mode == \"RGB\": image_resized = image.resize((size,size), resample=Image.BILINEAR) image_resized.save(to_path + \"/\" + file) #Saving the resized images \r\r (After resizing the images, all images are of 512 X 512 resolution.) \r","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:2:1","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Performing Data AugmentationAfter performing initial scrapping, I have fetched around 1100 paintings. Therefore, to increase the volume of training data, I have performed some data augmentation on scrapped paintings. For data augmentation, I have used the imgaug library. Following is the code snippet for data augmentation: from imgaug import augmenters as iaa num_augmentations = 2 #Number of augmentations that I want #Image Augmenter seq = iaa.Sequential([ iaa.Fliplr(0.5), iaa.PerspectiveTransform(scale=(0.0, 0.2), mode='replicate'), iaa.AddToHueAndSaturation((-20, 20)) ]) The reason behind using the number of augmentations as 2 is just heuristics. I have used the StyleGAN2 ADA model, this model has adaptive discriminator augmentation that will take care of further necessary augmentation. ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:2:2","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Transforming images into TF.RecordsOne another step in pre-processing is to transform the images into TF.records(creating the dataset). Again, Nvidia’s StyleGAN2 has an inbuilt option to create the dataset. First and foremost, we have to make sure we are using the TensorFlow 1.x version because Nvidia continued using this version of the TensorFlow. %tensorflow_version 1.x Following is the code snippet for creating the dataset: #First of all we have to clone Nvidia's StyleGAN2 repo %cd \"/content/drive/My Drive/Project\" #directory of my project !mkdir colab-sg2-ada %cd colab-sg2-ada !git clone https://github.com/dvschultz/stylegan2-ada #command for creating dataset !python dataset_tool.py create_from_images \"/content/drive/My Drive/Project/Images\" '/content/drive/My Drive/Project/Dataset' ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:2:3","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Training the modelOnce we have the dataset, the next task is to train the model using the dataset. I have used Nvidia’s StyleGAN2 ADA model. StyleGAN is one of the most popular generative models by NVIDIA. Multiple versions of StlyeGAN have been released, and I have used the latest version, StyleGAN2-ADA. Training StyleGAN is computationally expensive; therefore, I have used Google colab pro to train the model. It took roughly two days to train the model. To train this model, make sure you are inside the directory of the cloned repository. Now, for training, we have to set specific hyperparameters. #how often should the model generate samples and a .pkl file snapshot_count = 10 #should the images be mirrored left to right? mirrored = True #should the images be mirrored top to bottom? mirroredY = False #metrics? metric_list = None #augments augs = \"bg\" Note that if your GPU is not that powerful, keep snapshot_count as minimum as possible(for, e.g., 5) and keep the metric_list as none. Now once you have set the hyperparameters, you can start the training process. !python train.py --outdir='/content/drive/MyDrive/Kaggle/Portrait/Results' --snap=snapshot_count --data='/content/drive/MyDrive/Kaggle/Portrait/Dataset_TF' --augpipe=augs --mirror=mirrored --mirrory=mirroredY --metrics=metric_list Now, once training has started, a new folder will be created inside the folder Results(in my case), and after every ten ticks, a .pkl will be saved there to represent the trained model. When to stop training? There is no specific metric to judge the training when it comes to Generative Modelling. What I did, was to check after every few hours the status of the snapshot. the training process yields the output of the model along with saving its .pkl file. I kept checking the output, and when it finally started to resemble the portraits after a day or two, I stopped the training process as training further was not improving the output anymore. ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:3:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Generating PortraitsNow once you have trained the model, it is ready to generate portraits on its own. All you have to do is provide the random seed values to the generator. The generator will then produce portraits based on the given seed values. !python generate.py generate-images --network='/content/drive/MyDrive/Kaggle/Portrait/Results/final_model.pkl' --seeds=6600-6625 --outdir='/content/drive/MyDrive/Kaggle/Portrait/Output' In this case, I have provided seed values from 6600-6625. This will generate 25 portraits. Some of the generated portraits. \r\r\r\r\r","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:4:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Use of Transfer LearningOnce I finished training the model, I also tried the approach of Transfer Learning. Firstly I collected some random human faces that don’t exist. Once the dataset was ready, I used the trained model as a starting point and fine-tuned the model. Following are some sample portraits generated by the transfer learning model. \r\r\r","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:5:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Some Interesting IncidentsSo somewhere in between the training process, I found out a bizarre incident. Even though there were no paintings related to Jesus Christ in the dataset, it turns out in between the training process; there was a generated portrait resembling Jesus during the training process. GAN’s can be very interesting, but at the same time, they can produce unexplainable outcomes. \r\r\r","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:6:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Acknowledgement ‘GANs in Action’ by Jakub Langr and Vladimir Bok. MachineRay: Using AI to create Abstract art by Robert A. Gonsalves ","date":"2021-06-25","objectID":"/using-ai-to-create-portraits/:7:0","tags":null,"title":"GANArt: Using AI to create Portraits","uri":"/using-ai-to-create-portraits/"},{"categories":null,"content":"Hugo provides ","date":"2021-06-09","objectID":"/gans_in_industry/","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":" “Everything you can imagine is real.\" Pablo Picasso ","date":"2021-06-09","objectID":"/gans_in_industry/:0:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Introduction to Generative ModelingTo explain Generative Modeling in layman’s terms lets think of a scenario where our model is a classifier and given an image the model classifies it into a cat or dog image, now what if we want this process to go in the opposite direction where we provide a prescription of what we want to our model and model generates an image corresponding to that prescription, that is a generative model in its simplest form. Let us assume a dataset with data instances x and its corresponding label as y then there can be two types of modeling: Discriminative Modeling: It captures conditional probability p(y|x) Generative Modeling: It captures joint probability P(x,y) if its supervised learning otherwise P(x). \r(A simple illustration of how one can use discriminative vs generative models, img src:researchgate.net)\r In the case of generative modeling, the distribution p(x) is being learned and represented in latent space(z), latent space is a hidden representation of data point using which we try to generate x', this latent space z is learned representation which acts as inspiration so that we do not always get same x' as output. We humans also do something similar to it, lets take a scenario of reading a novel where x is the actual message author wants to convey different human being will have different interpretations z (unique hidden representation learnt by a human brain) and thus using these interpretations they will create their own understanding of author’s work x'. ","date":"2021-06-09","objectID":"/gans_in_industry/:1:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"What is a GAN ” Adversarial training is the most interesting idea in the last 10 years in ML\" Yann LeCun, the chief AI Scientist at Facebook Machine learning algorithms work great in recognizing patterns in existing data and using that insight for classification and regression purposes, however machine always struggled when asked to generate new data. This all changed in 2014 when Ian Goodfellow introduced Generative Adversarial Networks (GANs) to the world of machine learning, this technique enabled machines to generate realistic data. GANs are the class of ML techniques that consist of two simultaneously trained neural networks, one is Generator which is used to generate the fake data and other is Discriminator which is used to classify whether input given to it is real (image from training dataset) or fake (generated by the discriminator). The word generative in GAN indicates its sole purpose of generating new data, data that we want to generate depends on which dataset we have trained our GAN on. For example if we want to generate artwork similar to that of Pablo Picasso we will use his artwork as training dataset to train the GAN. The word adversarial refers to the game like competition between Generator and Discriminator where Generator tries to beat Discriminator by fooling it using its generated fake image in our example it means producing artwork exactly similar to that of Pablo Picasso’s whereas Discriminator objective is to discern the fake generated artwork from real. Finally the word network is used to indicate the class of ML technique that is used to represent Generator and Discriminator: Neural Networks. ","date":"2021-06-09","objectID":"/gans_in_industry/:2:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"GAN Architecture\r\r(This figure illustrates architecture of GAN) Let’s discuss details of the architecture: Training Dataset(x): The dataset that we want the Generator to learn from, it contains set of real examples. This dataset acts as input to discriminator network Random Noise Vector(z): This acts as raw input to the Generator network,Generator uses it as starting point for synthesizing fake examples. Generator network: It is a neural network which takes (z) as input and outputs fake examples (x*). Its goal is produce fake examples which are indistinguishable from the real examples. Discriminator network: It is a neural network which takes as input either real examples (x) or fake examples (x*) generated using Generator. Iterative training: Using classification error of Discriminator we iteratively tune the Discriminator and Generator networks through backpropagation. ","date":"2021-06-09","objectID":"/gans_in_industry/:3:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Training a GANAs we discussed earlier the term adversarial in GAN indicates the competitive dynamic between Generator and Discriminator, therefore, training a GAN includes simultaneous training of two different networks. The equilibrium state of GAN is defined as a NASH Equilibrium, it is a state when the discriminator is no longer able to classify between real data and fake data anymore(p(x)=0.5, p(x*)=0.5), in short, there is no room for more improvement left, and hence the training converges. ","date":"2021-06-09","objectID":"/gans_in_industry/:4:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Training the Discriminator network\r\r\ra. Take a random real example x from the training dataset. b. Pass random noise vector z as input to generator network and generate fake example x *. c. Classify x and x * using Discriminator network. d. Compute the classification error and backpropagate the total error to update the Discriminator weights and biases, seeking to minimize the classification errors. ","date":"2021-06-09","objectID":"/gans_in_industry/:4:1","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Training the Generator network \r\ra. Using random noise vector z as a input to the Generator network, synthesize a fake example x *. b. Use the Discriminator network to classify x *. c. Compute the classification error and backpropagate the error to update the Generator weights and biases, seeking to maximize the Discriminator’s error. ","date":"2021-06-09","objectID":"/gans_in_industry/:4:2","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Types of GAN","date":"2021-06-09","objectID":"/gans_in_industry/:5:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Deep Convolutional GAN(DCGANs)Instead of simple feed-forward neural networks, in case of DCGANs both our Generator and Discriminator is implemented as convolutional neural networks(CNNs). This architecture achieves superior performance in image-processing tasks. Although without breakthroughs such as batch normalization, DCGAN would fail to train properly. ","date":"2021-06-09","objectID":"/gans_in_industry/:5:1","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Conditional GANsThe Conditional GAN (CGAN) is one of the first GAN innovations that made targeted data generation possible. It is a GAN whose Generator and Discriminator are conditioned during training by using some additional information such as a class label, a set of tags, or even a written description. During training process the Generator learns to produce realistic images corresponding to each label in the training dataset, and the Discriminator learns to distinguish fake example-label pairs from real example-label pairs CGAN Generator Using random noise vector z and label y as inputs, the Generator produces a fake example x*|y that strives to be a realistic-looking match for the label. \r\r\rCGAN Discriminator The CGAN Discriminator receives real examples along with their labels (x, y) and fake examples along with the label used to synthesize them (x*|y, y). The Discriminator then outputs a probability (computed by the sigmoid activation function) indicating whether the input pair is real rather than fake. \r\r\r","date":"2021-06-09","objectID":"/gans_in_industry/:5:2","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"StackGANsIt is used to synthesize high-quality images from text descriptions, the main idea behind StackGANs is to decompose the hard problem into more manageable sub-problems using the sketch-refinement process. The Stage-1 GAN generates the primary shape and colors of the object based on the given text description. The Stage-2 GAN takes Stage-1 results and text description as input and generates high-quality images corresponding to the text description. \r\r(img source: Text to Photo-Realistic Image Synthesis by Vishal V, GitHub, https://github.com/Vishal-V/StackGAN) ","date":"2021-06-09","objectID":"/gans_in_industry/:5:3","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"CycleGANsThe CycleGAN is used for image-to-image translation which involves generating a new synthetic version of a given image with a specific modification, for example transforming horse image into image of zebra. CycleGAN is a technique that involves the automatic training of image-to-image translation models without paired examples. It is an unsupervised learning technique which requires collection of images from the source and target domain that do not need to be related in any way. \r\r(Transforming horse image into zebra image, src:tensorflow.org) ","date":"2021-06-09","objectID":"/gans_in_industry/:5:4","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Disco GANsAs its name suggests Discover Cross-Domain Relations GAN (DiscoGAN), it learns to discover relations between different domains. Using the discovered relations, the network transfers style from one domain to another. \r\r( image source: https://arxiv.org/pdf/1703.05192.pdf ) ","date":"2021-06-09","objectID":"/gans_in_industry/:5:5","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"GANs in Art IndustryIn 2018 AI-made portrait was sold at Christie’s auction for nearly half a million dollars and you will be surprised to know that a Picasso went for the same price. Fascinating as it sounds! It was made by the team called Obvious and they used none other than GANs. \r\r(Pierre Fautrel, co-founder of the team of French entrepreneurs called Obvious, which produces art using artificial intelligence, stands next to “Edmond de Belamy, from La Famille de Belamy.\") source: https://www.cnet.com/news/ai-made-portrait-sells-at-christies-auction-for-432500/ From portraits to abstract arts GANs can create anything. GAN has a bright scope in the field of Art and content creation. GANs can be used for recognizing the style of an art piece and then perfectly creating new original art by mimicking the style of the art piece. There is another fascinating project where we use GAN to create abstract art, GANGogh, where GAN is trained on a huge dataset of artistic works with different styles. Thus GAN generates art pieces by mixing those styles. \r\rSample artwork using GANGogh ","date":"2021-06-09","objectID":"/gans_in_industry/:6:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"GANs in Health CareGANs are utilized in improving diagnostic accuracy, before GANs were introduced Machine learning applications in health diagnosis faced a range of challenges, one of the challenges was to procure training datasets that are large enough to train supervised ML models due to difficulties involved in collecting medical data. The medical dataset is harder to come by, and they often require specialized equipment to collect. We have semi-supervised learning that helps to address the problem of small labeled datasets, this, however, addresses only half of the problem as in the case of semi-supervised learning we have a large dataset where only a small portion of the dataset is labeled, in healthcare applications this small portion is only data we have! For this problem, one of the solutions is to use standard data-augmentation techniques but using data-augmentation yields examples that do not diverge far from the original example and in the case of medical diagnostics, we want different examples of the same underlying pathology. Here comes GAN in the picture where it can be utilized to produce synthetic data to enlarge a training dataset. But GANs themselves need a lot of data to train, for this problem researchers brought an ingenious solution. First, they have used the standard data-augmentation techniques to create a larger dataset, and then they used this dataset to train a GAN to generate synthetic examples. This process further enriched the available dataset beyond standard data-augmentation techniques. Using GAN’s capability to synthesize high-quality images to enlarge the training dataset, in 2018 Frid-Adar decided to use GAN for medical data augmentation to improve the classification of liver lesions. The following chart shows their result: \r\r(This chart shows classification accuracy as new data is added on existing dataset using standard data-augmentation process and synthetic data generated using GAN. Source: Frid-Adar ., 2018, https://arxiv.org/abs/1803.01229 ) ","date":"2021-06-09","objectID":"/gans_in_industry/:7:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"GANs in Fashion IndustryUnlike healthcare, for which we faced the challenge of procuring training data, researchers in fashion industries are fortunate to have a huge training dataset. Retail giants such as Amazon and Flipkart have data on millions of purchases of every fashion item from hats to shoes, and sites such as Instagram and Pinterest have countless images of outfits. Such data availability provides an open room for AI researchers. \r\r\rIn 2017 retail giant Amazon using GAN developed an AI Fashion Designer, the story, published in MIT Technology Review, which only provided limited details about the project besides the mention of using GAN to design new customer-specific outfits. Also, using DiscoGANs one can utilize relation between different domains to perform a Style Transfer, if one wants to generate matching pair of shoes to their jacket, Style Transfer can do that. ","date":"2021-06-09","objectID":"/gans_in_industry/:8:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Few other Industrial Use Cases","date":"2021-06-09","objectID":"/gans_in_industry/:9:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Gaming Industry What if we could train an AI model to draw new worlds based on video from the real world ? In 2018 Nvidia presented a new GAN-based AI technology at the NeurIPS conference that can automatically generate realistic virtual worlds. The below video features their work where the virtual world is not created by a graphics engine but rendered by a technology built by Nvidia by training a neural network on videos of cities to render urban environments. These interactive 3D virtual worlds can be utilized by the gaming industries to make games whose experience is nothing compared to the games that we play today, games like GTA5 which is entirely based on the 3D virtual world can utilize this tool to maximize user experience. \r\r\r","date":"2021-06-09","objectID":"/gans_in_industry/:9:1","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Generating MusicIt is of no surprise that GANs can be utilized to compose music, whenever there is room for creativity one can surely apply GAN. In 2016, Olof Mogren presented a paper where he proposed a GAN that can work well on continuous sequential data, he introduced C-RNN-GAN where discriminator and generator are two different deep recurrent neural networks, he trained this model on a collection of classical music. The resulting model generated music, here I have added a sample of music that his model has generated. \rYour browser does not support the audio element.\r\rYour browser does not support the audio element.\r\rsource: Olof Mogren, http://mogren.one/publications/2016/c-rnn-gan/ \r","date":"2021-06-09","objectID":"/gans_in_industry/:9:2","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Drug Discovery and DevelopmentWhile most researchers have used GANs to work with image, video, and speech, few researchers from Insilico Medicine have proposed a method to use GAN in drug discovery and development. As there are already existing drugs for a certain disease, using this we can have a Generator network to sample drug candidates for that disease that can be as effective as real ones. ","date":"2021-06-09","objectID":"/gans_in_industry/:9:3","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Generating Website designsDesigning a website is a manual process that requires creative thinking and a lot of hard work as it is a skilled process. But again whenever there is room for creativity one can surely apply GAN. GAN can be utilized to design websites, once GAN is trained on various website designs it can come up with an initial design of a website, this initial design can be a great help to designers. ","date":"2021-06-09","objectID":"/gans_in_industry/:9:4","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Creating InfographicsInfographics are used as a powerful tool to convey information easily through the use of visual data and statistics. It requires a lot of hard work to design an Infographic it consists of planning the infographic design, selecting the right infographic layout, incorporating different Infographic design elements, and many more. GANs can help the designers to come up with a new unique design by sampling existing designs, this generated design can act as an inspiration to a designer. ","date":"2021-06-09","objectID":"/gans_in_industry/:9:5","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":"Drawbacks While discussing the training of GAN I have used a term called Nash Equilibrium, which is a condition where the discriminator is no longer able to classify between real data and fake data anymore. Achieving a Nash Equilibrium while training a GAN is very difficult, thus, training of GAN is highly unstable and its convergence may often fail. If the data that we have is highly complex and has multi-modal distribution, GAN will not be able to represent it. This issue restricts GAN’s ability to produce diverse results. ","date":"2021-06-09","objectID":"/gans_in_industry/:10:0","tags":null,"title":"GANs in Industry","uri":"/gans_in_industry/"},{"categories":null,"content":" I am currently pursuing my masters in Data Science from Defence Institute Of Advanced Technology(DRDO), I like to build things and understand the problems that one cannot see through a strictly theoretical perspective. The process of theory and skills merging to develop a product excites me which led me towards the vast field of data science. Here I express my understanding of various concepts of Machine Learning and Mathematics. ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"Know Your Plant(06/2021 - 07/2021) Know your plant is an android application. This application is built using the Kivy framework. For example, users can upload a photograph of a leaf of their garden plant; not only will it classify the category of the leaf, but it will also give the plant’s health status. Also, one can upload a photograph of a flower, and this application will also detect the flower category. Github Link for the project. APK file for this application ","date":"0001-01-01","objectID":"/projects/:1:0","tags":null,"title":"Projects","uri":"/projects/"},{"categories":null,"content":"GANArt: Using AI to create Portraits(05/2021 - 06/2021) This project aims to mimic the artist’s painting style and make a portrait on its own, this project uses Nvidia’s StyleGAN2( Style Generative Adversarial network) model Github Link for the project. ","date":"0001-01-01","objectID":"/projects/:2:0","tags":null,"title":"Projects","uri":"/projects/"},{"categories":null,"content":"UDBI( Universal Database Integration)Using Database Interface, one can interact with any back end software (i.e. Oracle, MS-SQL Server, MS- Access, My-SQL etc). The database interface can be used to build, test, and debug PL/SQL packages, procedures, triggers, and functions. Database Interface users can create and edit database objects such as tables, views, indexes, constraints, and users. Github Link for the project. ","date":"0001-01-01","objectID":"/projects/:3:0","tags":null,"title":"Projects","uri":"/projects/"}]